{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T18:23:33.429853Z",
     "start_time": "2020-07-15T18:23:32.862622Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T18:23:35.422317Z",
     "start_time": "2020-07-15T18:23:35.416362Z"
    }
   },
   "outputs": [],
   "source": [
    "# grab NYT githhub data\n",
    "url_county = 'https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv'\n",
    "url_state = 'https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-states.csv'\n",
    "url_country = 'https://raw.githubusercontent.com/nytimes/covid-19-data/master/us.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T18:23:42.599389Z",
     "start_time": "2020-07-15T18:23:39.393722Z"
    }
   },
   "outputs": [],
   "source": [
    "county_data = pd.read_csv(url_county)\n",
    "state_data = pd.read_csv(url_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T18:23:43.885276Z",
     "start_time": "2020-07-15T18:23:43.791498Z"
    }
   },
   "outputs": [],
   "source": [
    "county_data = county_data[~county_data['state'].isin(['District of Columbia','Northern Mariana Islands','Guam','Puerto Rico','Virgin Islands'])].reset_index(drop=True)\n",
    "state_data = state_data[~state_data['state'].isin(['District of Columbia','Northern Mariana Islands','Guam','Puerto Rico','Virgin Islands'])].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T18:23:50.382221Z",
     "start_time": "2020-07-15T18:23:50.289474Z"
    }
   },
   "outputs": [],
   "source": [
    "county_data=county_data.dropna(subset=['county'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T18:23:51.998678Z",
     "start_time": "2020-07-15T18:23:51.985712Z"
    }
   },
   "outputs": [],
   "source": [
    "def classification_average_cases_change(updown,x):\n",
    "    if updown=='decrease' and x>=15:\n",
    "        return 'falling'\n",
    "    \n",
    "    elif updown=='decrease' and x<15:\n",
    "        return 'about the same'\n",
    "    \n",
    "    elif updown=='change':\n",
    "        return 'about the same'\n",
    "    \n",
    "    elif updown=='increase' and x<50:\n",
    "        return 'about the same'\n",
    "    \n",
    "    elif updown =='increase':\n",
    "        if x >=50 and x<200:\n",
    "            return 'great'\n",
    "        if x >=200 and x<300:\n",
    "            return 'greater'\n",
    "        if x >=300:\n",
    "            return 'greatest'\n",
    "    else:\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T18:23:57.019723Z",
     "start_time": "2020-07-15T18:23:54.552332Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Washington\n",
      "Illinois\n",
      "California\n",
      "Arizona\n",
      "Massachusetts\n",
      "Wisconsin\n",
      "Texas\n",
      "Nebraska\n",
      "Utah\n",
      "Oregon\n",
      "Florida\n",
      "New York\n",
      "Rhode Island\n",
      "Georgia\n",
      "New Hampshire\n",
      "North Carolina\n",
      "New Jersey\n",
      "Colorado\n",
      "Maryland\n",
      "Nevada\n",
      "Tennessee\n",
      "Hawaii\n",
      "Indiana\n",
      "Kentucky\n",
      "Minnesota\n",
      "Oklahoma\n",
      "Pennsylvania\n",
      "South Carolina\n",
      "Kansas\n",
      "Missouri\n",
      "Vermont\n",
      "Virginia\n",
      "Connecticut\n",
      "Iowa\n",
      "Louisiana\n",
      "Ohio\n",
      "Michigan\n",
      "South Dakota\n",
      "Arkansas\n",
      "Delaware\n",
      "Mississippi\n",
      "New Mexico\n",
      "North Dakota\n",
      "Wyoming\n",
      "Alaska\n",
      "Maine\n",
      "Alabama\n",
      "Idaho\n",
      "Montana\n",
      "West Virginia\n"
     ]
    }
   ],
   "source": [
    "def gather_data_state(data,loc):\n",
    "    print(loc)\n",
    "#     daily_cases = pd.DataFrame()\n",
    "#     daily_deaths = pd.DataFrame()\n",
    "    totals = pd.DataFrame()\n",
    "    present_day = []\n",
    "    \n",
    "    \n",
    "    if len(data['cases'])>14:\n",
    "\n",
    "        daily_cases = np.zeros(len(data['cases']))\n",
    "        daily_cases[0] = data['cases'].iloc[0]\n",
    "        \n",
    "        daily_deaths = np.zeros(len(data['deaths']))\n",
    "        daily_deaths[0] = data['deaths'].iloc[0]\n",
    "\n",
    "        # for loop checks to see if data reports a negative daily cases number.  If it does, the number is recorded as zero instead\n",
    "        for idx in np.arange(1,len(data['cases'])):\n",
    "            daily_cases[idx] = max(data['cases'].iloc[idx]-data['cases'].iloc[idx-1],0)\n",
    "            daily_deaths[idx] = max(data['deaths'].iloc[idx]-data['deaths'].iloc[idx-1],0)\n",
    "            \n",
    "        daily_cases=pd.DataFrame(daily_cases,columns=['daily_cases'])\n",
    "        daily_deaths=pd.DataFrame(daily_deaths,columns=['daily_deaths'])\n",
    "        # calculate averages\n",
    "        sevenMA = daily_cases['daily_cases'].rolling(window=7).mean()\n",
    "        sevenMAdeath = daily_deaths['daily_deaths'].rolling(window=7).mean()\n",
    "        sevenMA1diff = sevenMA.diff(periods=6)\n",
    "        sevenMA2diff = sevenMA.diff(periods=13)\n",
    "        twoweekMA = daily_cases['daily_cases'].rolling(window=14).mean()\n",
    "        twoweekMAdiff = twoweekMA.diff(periods=13)\n",
    "        cumsum_cases=daily_cases['daily_cases'].cumsum()\n",
    "        cumsum_deaths=daily_deaths['daily_deaths'].cumsum()\n",
    "        sevenMAcumsum= state['cases'].rolling(window=7).mean()\n",
    "        data['sevenMA'] =sevenMA\n",
    "        data['sevenMA1diff']= sevenMA1diff\n",
    "        data['sevenMA2diff']= sevenMA2diff\n",
    "        data['twoweekMA']=twoweekMA\n",
    "        data['twoweekMAdiff']=twoweekMAdiff\n",
    "        data['sevenMAcumsum']=sevenMAcumsum\n",
    "        data['daily_cases']=daily_cases['daily_cases'].values\n",
    "        data['daily_deaths']=daily_deaths['daily_deaths'].values\n",
    "        data['cumsum_cases']=cumsum_cases\n",
    "        data['cumsum_deaths']=cumsum_deaths\n",
    "        data['sevenMAdeaths']=sevenMAdeath\n",
    "        totals = totals.append(data)\n",
    "\n",
    "        # gather information\n",
    "        present_day.append((data['date'].iloc[-1],\n",
    "                         data['state'].iloc[-1],\n",
    "                         cumsum_cases.iloc[-1],\n",
    "                         cumsum_deaths.iloc[-1],\n",
    "                         daily_cases['daily_cases'].iloc[-1],\n",
    "                         sevenMA.iloc[-1],\n",
    "                         sevenMA.iloc[-7],\n",
    "                         sevenMA.iloc[-14],\n",
    "                         sevenMA1diff.iloc[-1],\n",
    "                         sevenMA2diff.iloc[-1],\n",
    "                         twoweekMA.iloc[-1],\n",
    "                         twoweekMA.iloc[-14],\n",
    "                         twoweekMAdiff.iloc[-1]\n",
    "                        ))   \n",
    "    \n",
    "\n",
    "        info=pd.DataFrame(present_day,columns=['date','state','cumsum_cases','cumsum_deaths','daily_cases','sevenMA','sevenMA1wktrailing',\n",
    "                                            'sevenMA2wktrailing','sevenMA1wkdiff','sevenMA2wkdiff',\n",
    "                                            'twoweekMA','twoweekMAtrailing','twoweekMAdiff'])\n",
    "\n",
    "        # creating categorical values based on averages\n",
    "        info['avg_7_1wk_change_dir']=info['sevenMA1wkdiff'].map(lambda x: 'increase' if x>0 else('change' if x==0 else 'decrease'))\n",
    "        info['avg_7_2wk_change_dir']=info['sevenMA2wkdiff'].map(lambda x: 'increase' if x>0 else('change' if x==0 else 'decrease'))\n",
    "        # address dividing by zero\n",
    "        # counties['sevenMA1wktrailing']=counties['sevenMA1wktrailing'].replace(0,1e-6)\n",
    "        # counties['sevenMA2wktrailing']=counties['sevenMA2wktrailing'].replace(0,1e-6)\n",
    "\n",
    "        info['avg_14_change_dir']=info['twoweekMAdiff'].map(lambda x: 'increase' if x>0 else('change' if x==0 else 'decrease'))\n",
    "        # counties['twoweekMAtrailing']=counties['twoweekMAtrailing'].replace(0,1e-6)\n",
    "\n",
    "\n",
    "\n",
    "        info['avg_7_1wk_pct_change']= 100*info['sevenMA1wkdiff'].abs() / info['sevenMA1wktrailing']\n",
    "        info['avg_7_2wk_pct_change']= 100*info['sevenMA2wkdiff'].abs() / info['sevenMA2wktrailing']\n",
    "        info['avg_14_pct_change']= 100*info['twoweekMAdiff'].abs() / info['twoweekMAtrailing']\n",
    "\n",
    "        info['case7_1wk_change'] = info.apply(lambda x: classification_average_cases_change(x['avg_7_1wk_change_dir'], x['avg_7_1wk_pct_change']), axis=1)\n",
    "        info['case7_2wk_change'] = info.apply(lambda x: classification_average_cases_change(x['avg_7_2wk_change_dir'], x['avg_7_2wk_pct_change']), axis=1)\n",
    "        info['case14_change'] = info.apply(lambda x: classification_average_cases_change(x['avg_14_change_dir'], x['avg_14_pct_change']), axis=1)\n",
    "\n",
    "        return totals, info\n",
    "    \n",
    "    else:\n",
    "        print('pass')\n",
    "\n",
    "        return totals, totals\n",
    "\n",
    "\n",
    "all_state_totals=pd.DataFrame()\n",
    "all_states_present_day=pd.DataFrame()\n",
    "i=0\n",
    "for state_loc in state_data['state'].unique():\n",
    "    i=i+1\n",
    "    state=pd.DataFrame(state_data.loc[state_data['state']==state_loc].sort_values(['date'], ascending=True)).reset_index(drop=True)\n",
    "    state_totals, states_present_day = gather_data_state(state,state_loc)\n",
    "    all_state_totals = all_state_totals.append(state_totals)\n",
    "    all_states_present_day=all_states_present_day.append(states_present_day)\n",
    "    \n",
    "\n",
    "all_states_present_day=all_states_present_day.sort_values(by=['cumsum_cases'],ascending=False).reset_index(drop=True)\n",
    "all_states_present_day=all_states_present_day.reset_index()\n",
    "all_states_present_day['index']=all_states_present_day['index']+1\n",
    "\n",
    "\n",
    "all_state_totals.to_csv('state_totals.csv',index=False)\n",
    "all_states_present_day.to_csv('states_present_day.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-11T16:16:14.864971Z",
     "start_time": "2020-07-11T16:16:14.688471Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-11T16:16:14.864971Z",
     "start_time": "2020-07-11T16:16:14.688471Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T18:29:22.470336Z",
     "start_time": "2020-07-15T18:24:02.731094Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 + Washington\n",
      "2 + Illinois\n",
      "3 + California\n",
      "4 + Arizona\n",
      "5 + Massachusetts\n",
      "6 + Wisconsin\n",
      "7 + Texas\n",
      "8 + Nebraska\n",
      "9 + Utah\n",
      "10 + Oregon\n",
      "11 + Florida\n",
      "12 + New York\n",
      "13 + Rhode Island\n",
      "14 + Georgia\n",
      "15 + New Hampshire\n",
      "16 + North Carolina\n",
      "17 + New Jersey\n",
      "18 + Colorado\n",
      "19 + Maryland\n",
      "20 + Nevada\n",
      "21 + Tennessee\n",
      "22 + Hawaii\n",
      "23 + Indiana\n",
      "24 + Kentucky\n",
      "25 + Minnesota\n",
      "26 + Oklahoma\n",
      "27 + Pennsylvania\n",
      "28 + South Carolina\n",
      "29 + Kansas\n",
      "30 + Missouri\n",
      "31 + Vermont\n",
      "32 + Virginia\n",
      "33 + Connecticut\n",
      "34 + Iowa\n",
      "35 + Louisiana\n",
      "36 + Ohio\n",
      "37 + Michigan\n",
      "38 + South Dakota\n",
      "39 + Arkansas\n",
      "40 + Delaware\n",
      "41 + Mississippi\n",
      "42 + New Mexico\n",
      "43 + North Dakota\n",
      "44 + Wyoming\n",
      "45 + Alaska\n",
      "46 + Maine\n",
      "47 + Alabama\n",
      "48 + Idaho\n",
      "49 + Montana\n",
      "50 + West Virginia\n"
     ]
    }
   ],
   "source": [
    "def gather_data_county(data,loc):\n",
    "#     print(loc)\n",
    "    daily_cases = pd.DataFrame()\n",
    "    totals = pd.DataFrame()\n",
    "    present_day = []\n",
    "    \n",
    "    \n",
    "    if len(data['cases'])>14:\n",
    "\n",
    "        daily_cases = np.zeros(len(data['cases']))\n",
    "        daily_cases[0] = data['cases'].iloc[0]\n",
    "\n",
    "        # for loop checks to see if data reports a negative daily cases number.  If it does, the number is recorded as zero instead\n",
    "        for idx in np.arange(1,len(data['cases'])):\n",
    "            daily_cases[idx] = max(data['cases'].iloc[idx]-data['cases'].iloc[idx-1],0)\n",
    "            \n",
    "        daily_cases=pd.DataFrame(daily_cases,columns=['daily_cases'])\n",
    "        # calculate averages\n",
    "        sevenMA = daily_cases['daily_cases'].rolling(window=7).mean()\n",
    "        sevenMA1diff = sevenMA.diff(periods=6)\n",
    "        sevenMA2diff = sevenMA.diff(periods=13)\n",
    "        twoweekMA = daily_cases['daily_cases'].rolling(window=14).mean()\n",
    "        twoweekMAdiff = twoweekMA.diff(periods=13)\n",
    "        cumsum=daily_cases['daily_cases'].cumsum()\n",
    "        sevenMAcumsum= state['cases'].rolling(window=7).mean()\n",
    "        data['sevenMA'] =sevenMA\n",
    "        data['sevenMA1diff']= sevenMA1diff\n",
    "        data['sevenMA2diff']= sevenMA2diff\n",
    "        data['twoweekMA']=twoweekMA\n",
    "        data['twoweekMAdiff']=twoweekMAdiff\n",
    "        data['sevenMAcumsum']=sevenMAcumsum\n",
    "        data['daily_cases']=daily_cases['daily_cases'].values\n",
    "        data['cumsum']=cumsum\n",
    "        totals = totals.append(data)\n",
    "\n",
    "        # gather information\n",
    "        present_day.append((data['date'].iloc[-1],\n",
    "                         data['state'].iloc[-1],\n",
    "                         loc,\n",
    "                         cumsum.iloc[-1],\n",
    "                         daily_cases['daily_cases'].iloc[-1],\n",
    "                         sevenMA.iloc[-1],\n",
    "                         sevenMA.iloc[-7],\n",
    "                         sevenMA.iloc[-14],\n",
    "                         sevenMA1diff.iloc[-1],\n",
    "                         sevenMA2diff.iloc[-1],\n",
    "                         twoweekMA.iloc[-1],\n",
    "                         twoweekMA.iloc[-14],\n",
    "                         twoweekMAdiff.iloc[-1]\n",
    "                        ))   \n",
    "    \n",
    "\n",
    "        info=pd.DataFrame(present_day,columns=['date','state','county','cumsum','daily_cases','sevenMA','sevenMA1wktrailing',\n",
    "                                            'sevenMA2wktrailing','sevenMA1wkdiff','sevenMA2wkdiff',\n",
    "                                            'twoweekMA','twoweekMAtrailing','twoweekMAdiff'])\n",
    "\n",
    "        # creating categorical values based on averages\n",
    "        info['avg_7_1wk_change_dir']=info['sevenMA1wkdiff'].map(lambda x: 'increase' if x>0 else('change' if x==0 else 'decrease'))\n",
    "        info['avg_7_2wk_change_dir']=info['sevenMA2wkdiff'].map(lambda x: 'increase' if x>0 else('change' if x==0 else 'decrease'))\n",
    "        # address dividing by zero\n",
    "        # counties['sevenMA1wktrailing']=counties['sevenMA1wktrailing'].replace(0,1e-6)\n",
    "        # counties['sevenMA2wktrailing']=counties['sevenMA2wktrailing'].replace(0,1e-6)\n",
    "\n",
    "        info['avg_14_change_dir']=info['twoweekMAdiff'].map(lambda x: 'increase' if x>0 else('change' if x==0 else 'decrease'))\n",
    "        # counties['twoweekMAtrailing']=counties['twoweekMAtrailing'].replace(0,1e-6)\n",
    "\n",
    "\n",
    "\n",
    "        info['avg_7_1wk_pct_change']= 100*info['sevenMA1wkdiff'].abs() / info['sevenMA1wktrailing']\n",
    "        info['avg_7_2wk_pct_change']= 100*info['sevenMA2wkdiff'].abs() / info['sevenMA2wktrailing']\n",
    "        info['avg_14_pct_change']= 100*info['twoweekMAdiff'].abs() / info['twoweekMAtrailing']\n",
    "\n",
    "        info['case7_1wk_change'] = info.apply(lambda x: classification_average_cases_change(x['avg_7_1wk_change_dir'], x['avg_7_1wk_pct_change']), axis=1)\n",
    "        info['case7_2wk_change'] = info.apply(lambda x: classification_average_cases_change(x['avg_7_2wk_change_dir'], x['avg_7_2wk_pct_change']), axis=1)\n",
    "        info['case14_change'] = info.apply(lambda x: classification_average_cases_change(x['avg_14_change_dir'], x['avg_14_pct_change']), axis=1)\n",
    "        return totals, info\n",
    "\n",
    "\n",
    "    else:\n",
    "#         print('pass')\n",
    "        return totals,totals\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "all_county_totals=pd.DataFrame()\n",
    "all_county_present_day=pd.DataFrame()\n",
    "i=0\n",
    "for state_loc in county_data['state'].unique():\n",
    "    i=i+1\n",
    "    print(i,'+',state_loc)\n",
    "    state=pd.DataFrame(county_data.loc[county_data['state']==state_loc].sort_values(['date'], ascending=True)).reset_index(drop=True)\n",
    "    for county_loc in state['county'].unique():\n",
    "        county=pd.DataFrame(state.loc[state['county']==county_loc].sort_values(['date'], ascending=True)).reset_index(drop=True)\n",
    "        county_totals, county_present_day = gather_data_county(county,county_loc)\n",
    "        all_county_totals = all_county_totals.append(county_totals)\n",
    "        all_county_present_day=all_county_present_day.append(county_present_day)\n",
    "\n",
    "all_county_totals.to_csv('county_totals.csv',index=False)\n",
    "all_county_present_day.to_csv('counties_present_day.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
